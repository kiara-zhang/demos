{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0xDYaGkru93"
      },
      "source": [
        "# DL-Guided Cross-Species Gene Sequence Optimization (a VERY NAIVE demo)\n",
        "\n",
        "**This is essentially just an extremely naive demo I played around with before starting uni to get familiarised with the field.**\n",
        "\n",
        "---\n",
        "\n",
        "> *In-silico horizontal gene transfer*\n",
        "\n",
        "![align1](./img/align_pr1.png)\n",
        "\n",
        "The project was initially developed as the dry-lab component of my iGEM team’s synthetic biology project. While entirely illustrative in nature (and independent of our wet-lab experiments, where plasmids for actual biotransformation are transferred across two bacterial species), the primary aim is to deepen my understanding of computational biology. I personally find the field extremely fascinating, and over the past few weeks, the whole process of designing the pipeline, researching algorithms, and implementing (plus so much debugging...) the code has been both rewarding and incredibly fun.\n",
        "\n",
        "The central idea behind the pipeline is that the base model (in this case [Evo-1](https://github.com/evo-design/evo/)) captures general *prokaryotic* genomic patterns, while fine-tuning on the target host species' DNA corpus enables it to learn host-specific contextual information. This, in turn, helps reveal how 'host-like' a candidate sequence is, thereby guiding sequence optimization. This 'mutagenesis' step is carried out via an iterative, directed-evolution–like MH-MCMC sampling procedure, which recursively proposes point mutations on the current sequence while protecting the enzyme's active site from non-synonymous substitutions. Finally, optimized sequences are evaluated by calculating CAI and GC content to assess host compatibility, and by performing structural predictions to visualize the structures of the new proteins (via PyMol) and compute further metrics (pLDDTs and scores for alignment with reference sequence).\n",
        "\n",
        "(Regarding the 'gradient-based sensitivity analysis' step, I also ran a demo with [Nucleotide Transformer](https://github.com/instadeepai/nucleotide-transformer), another DNA (masked) LM yet not at single-nt resolution and not trained specifically on prokaryotic genomes.)\n",
        "\n",
        "More details on the pipeline can be found within the notebook cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yyq4OqYIq6O6",
        "outputId": "59cf78d4-cf7e-4977-ccb2-5e5573a8391a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully installed!\n",
            "Evo-1 is a DNA language model (more specifically, a GPT-styled causal LM that can be used for generation and scoring tasks based on log-likelihood of the next token) trained on **prokaryotic** whole-genome sequences at a single-nucleotide, byte-level resolution.\n"
          ]
        }
      ],
      "source": [
        "# Section 1: preparation\n",
        "\n",
        "\n",
        "!pip install --upgrade evo-model biopython transformers accelerate datasets peft > /dev/null 2>&1\n",
        "print('Successfully installed!')\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoConfig, AutoModelForCausalLM,\n",
        "    DataCollatorForLanguageModeling, Trainer, TrainingArguments, BitsAndBytesConfig\n",
        ")\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import zipfile\n",
        "import random\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "# We use Evo-1 as the base model, with the checkpoint 'for molecular-scale finetuning tasks' (the other one pretrained with 131,072 context is said to be for tasks 'at the genome scale')\n",
        "print('Evo-1 is a DNA language model (more specifically, a GPT-styled causal LM that can be used for generation and scoring tasks based on log-likelihood of the next token) trained on **prokaryotic** whole-genome sequences at a single-nucleotide, byte-level resolution.')\n",
        "model_name = 'togethercomputer/evo-1-8k-base'\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sOLInmyP_2y",
        "outputId": "c487f98a-24aa-43a8-ba2d-af002818bd09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 18.2M  100 18.2M    0     0  12.9M      0  0:00:01  0:00:01 --:--:-- 12.9M\n",
            "Genome downloaded!!\n",
            "Found .gbff file:, genome_data/ncbi_dataset/data/GCF_000739105.1/genomic.gbff!\n",
            "Extracted 7474 coding DNA sequences!\n",
            "[{'sequence': 'ATGGCACCGAAGACCGAACGCATCCAGTTCCTGCGGGCCGTGCGGCAGCTGCGCCGGATCCGCTCCTTCTACGCTGCGGCCGTTCTGCTGTGGACGGGGAGCACTGCCTGGACGGGTTGGCAGGCTCCGGGGAGCCGGCAGATGTGGGTGTCCGTTCTCCTCCTGGCCGTCTTCGCCGTACTGCTCGTCACCGCGAGCCTCGCCCTGCGGCGTCTCGCCGTTCCCGCAACGGGCCGGCCCGTGCACCACGCTGCCCCGCACAAGCTGCCGAGCATCCGTCGTCACGCTCACGCCTGA'}, {'sequence': 'GTGGAGATCAGTGAGTACGAGACCCTCTCCATACTCCTGGATGCTGAGGCGGATCCGAACGAGGTGTGCTTCGGGCTCACGTTGCTGACCCAGCGGCTGCTCCAGCGCTTCCTCACCCTCACCCCGGCCAAATCCGCAGGGAGCGCGCGTGACGAATGA'}, {'sequence': 'GTGACGAATGATCACGGGCCGTCGCCCCTCGGCTCGGGCTCCCCTTACAGCGACGCCTCGATCTACGTGGACGCGGAGGCCGCCCCGCGGATCATGGCCCGGCTTCGAGACGCCCTCGGCCTCGTCGAGGACGACGGTCCAGAGCTGGCAATCGGGCCGGTGCGCGTGACCGGCGCGCCAAACGACTACGCCACAGGCCGGCGCGCTCACCCCTTCGACTTCCTGGAATGGCCGACCGTGCTGGAGTGCGAGGCCTCCGAGGGGACACGTGCCGAGGTGGTGCAGGCCGTCACGGCCGTGCTCGAAGCGCTGTGGCACGGTGGCTTCAAAGCTGTAGCCGCCTGCGACTTCGAGGACGGGTTGCCCGCGCGCGGCGGGATCGACAGGTACCTCTACCCCGCTCCTGCCCCCGACGGGGGCGCGGTCTTTTCGGGCACGGGTACGTGGTGGAGGAACCTGATGTCGCCCGGAAAAAGGAAAGGTCGAAATCTGTGA'}]\n",
            "Dataset created:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sequence'],\n",
            "        num_rows: 6726\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sequence'],\n",
            "        num_rows: 748\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Section 2: dataset creation for fine-tuning\n",
        "\n",
        "\n",
        "# Install NCBI Datasets CLI (documentation: https://www.ncbi.nlm.nih.gov/datasets/docs/v2/)\n",
        "!curl -o datasets 'https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/v2/linux-amd64/datasets'\n",
        "!chmod +x datasets\n",
        "\n",
        "# Download host genome by NCBI Assembly accession\n",
        "accession = 'GCF_000739105.1'  # RefSeq; our target host species: Streptomyces lividans TK24\n",
        "# GenBank FlatFile (.gbff) includes genomic sequence and annotations for the following CDS extraction!\n",
        "!./datasets download genome accession {accession} --include gbff --filename genome.zip > /dev/null 2>&1\n",
        "print('Genome downloaded!!')\n",
        "\n",
        "# Unzip and locate .gbff file\n",
        "with zipfile.ZipFile('genome.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('genome_data')\n",
        "gbff_path = None\n",
        "for root, _, files in os.walk('genome_data'):\n",
        "    for file in files:\n",
        "        if file.endswith('.gbff'):\n",
        "            gbff_path = os.path.join(root, file)\n",
        "            break\n",
        "print(f'Found .gbff file:, {gbff_path}!')\n",
        "\n",
        "cds_sequences = []\n",
        "for record in SeqIO.parse(gbff_path, \"genbank\"):\n",
        "    for feature in record.features:\n",
        "        if feature.type == \"CDS\":\n",
        "            cds_seq = feature.location.extract(record).seq\n",
        "            cds_sequences.append({\"sequence\": str(cds_seq).upper()})\n",
        "print(f'Extracted {len(cds_sequences)} coding DNA sequences!')\n",
        "print(cds_sequences[:3])\n",
        "\n",
        "# Create HuggingFace Dataset\n",
        "dataset = Dataset.from_list(cds_sequences)\n",
        "# Split the dataset\n",
        "split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "print('Dataset created:')\n",
        "print(split_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ee1a25e976a742d29a58b84802649ae0",
            "d8a3abe77fdf4e18aa0005add66c7668",
            "13282214288a42168192c0ed08d730cb",
            "5e3cc5f1dde747c0a06e794c45fada5f",
            "928b661843b6489fa3f69b7bb61898ee",
            "76eda77650a64a0d9c671cf4b8cec28b",
            "cc75c8910512453285c54284e6e0317c",
            "dab17db72e97482581263cd064b381a9",
            "7abd2423ea2b4b1591fc74295303dbde",
            "6af69b659975469694406a9a3daf4bc6",
            "c0aecb39233246e0a39ce625878309fe",
            "8f0ea70201c84434b0b0ac410422cb9c",
            "74bc8202bbe74ac3914d6e42e0a46de2",
            "b82b9c746ce64415a84020ad6bb3647a",
            "693fdcb60d1a467384ffc4a3fe71b564",
            "5c490e5d0a6b44e4bde3cf2bf9dbe289",
            "36c7fb0018534eb18d5797b0970f0ab1",
            "d659ab6b8727443d9a25df16c9e3ddfa",
            "e623a9dc036349969178f0000d2b8e9e",
            "d4ec40b1968c4a7a80dcd17d5253010c",
            "d310d1dde71847f093bc44761de3c329",
            "624d7d5719d34a68bd14b8f18a4056bf",
            "4a533929dc864acca00080e72dbb8b72",
            "31c8f84824ef4d2fa85e1e7a3611bbd8",
            "d52df80144874829b51a43c3a00b8b6e",
            "5c1f32e541e24d4fa28af2b7073ea834",
            "78576c1fe597470ba601fdcbb72503d7",
            "66cbc731a9b04a73b1ad4fe47589a73e",
            "004c867229714b6cbfcf135975d37497",
            "5c3be72da76246eb92dcf5e528caa142",
            "20615b9bc5b8420c9bbe2fab76ab64f0",
            "b7b06ad166cc437e921b3d96266ca8a7",
            "a3595941087849d4a3fb1b9f5734241b",
            "a38588c725aa44e8a701833820c59cbb",
            "5b14a2689caf4a3795c82355af58d85b",
            "3c8a67e401ff4f6cad4202479fbb0fa6",
            "f2ae6017c9da45218d97e781af46ec43",
            "8f96c86c09514ad295856fe10b20e6c4",
            "70712248ce474ca5969937752e691f34",
            "d5865077ccec40f6b5d7a9229b67f5ce",
            "f21d0214c30a4e9cbf808be79134f7fb",
            "3cc5704ff63042c3ae66bbef6fe181e1",
            "9d81a68de4ef484299e44ef2598b09ab",
            "cea793f16adc49f2a3ba8d27b437ff3c",
            "89251f6caa6741008fb8c6311392b378",
            "bea3fc4ef4f240bc83fe93412fb233b3",
            "71be73e632054682bbb23086b4bbee3c",
            "674c342d330b476cbf5a4bb33b36a2b5",
            "4b42a26851234a4e8e1ad6ac43dceec2",
            "ed307859de7845f581408a148cfc6eba",
            "4447399cd77045b2b2fe3f44e7af1aff",
            "1101ea7d8c564ae68f41acc171a07782",
            "aafc4e0eb57f4eef8f454b11400bd42c",
            "166dd890d178400197a214f2d71d7dd3",
            "cb49373d2c56441e8df91c85997a9f3b",
            "308c11c21e624e6aa75d1632182cdb77",
            "df4683c5ce984d2182e97eaeb9281be0",
            "f9c845e67a73436283f71bdb79a5a244",
            "a90042d9f98c4de69e402565407508d2",
            "15c8842df37543a3a47dd3e3a8e44792",
            "010f6bc20e5c4248aad7ef41e081d7c1",
            "d0d7083541014fe49805cdf4295fdeb6",
            "60e64112d0504d6c979f2c586a43c912",
            "196e2c04b43e470b99d05767920abb56",
            "9340ef4dc2a4484db8ccb74a347f212e",
            "b6bf2a2ee2b44bc6b65dc9a9bb950839",
            "d25283b4698945bfbb656701e2fa5a52",
            "2f739f0b5ad74bdda5786a4c04cc9fb2",
            "07a5dd2985e145d9873e12d59279ce5f",
            "ceb8c493b837423f816b0ac3e9d4ff32",
            "f464cd5e541044398f0b152641671494",
            "8b9f274fcd8e428e898bc7f76515ea30",
            "c46e25021b6e4480bf2055aefa029e35",
            "c00ed99275e34cce849b6d04afb91b83",
            "148b8f0dfcec4db089fe35c186789c9d",
            "e07eeb269cb94fbf8aa91c09a9772fae",
            "4083d2fc9f7f4906896c6d2f01496595",
            "81109743f33441a18dd0520930ace72f",
            "9b286153f9a74bb99c07c369340794e9",
            "cd1f13d5eb7d49c2866cbbd3b5d12e6e",
            "ee8b0667d3b7453ebd8efd9d64b3e942",
            "764e3756f665413aa7bf9ae36234c5be",
            "a72f43b5083e43a5908a7207229d3ffa",
            "112408e919fa4ead9a9156de1742f391",
            "5d2051475ba948dead75210593954312",
            "c6ae7cb8228f4a14889b766152bd4199",
            "e1beda0edacd4544932dc4534534b015",
            "9a21caa7319645a895c3c2c2060380f3",
            "f7f2cfd706af40198d12972d31889af3",
            "8314b4c191d74c99907a12b8ca8de892",
            "f8927913be0b47cc99141b63992dc762",
            "45dba92e1ba949a5b7717dbd774935fb",
            "6253cceb155f42b4ba2884bf2cac8da3",
            "b6d0a827122c4820a551ce896214de03",
            "5f802471344044f598d032af60f96949",
            "b4a0a46a182a4e09a1674302ed837bda",
            "b6b8d2afc29d461eb756394d7123c62d",
            "65d1c36fb55c465d97a87faa61537f85",
            "0dbee7c29cef48748e2ad789a1926e8e",
            "259c0663c3bb495aa577a646c36771f5",
            "12e4a1dc5ed64e54b7aa8d8726657028",
            "2f25bc373b8e40a78e15af8f0f0770a1",
            "886c57c48b3a49ad8475788f31b85a68",
            "1175fecf801249e9bbabcaa72da5373b",
            "b4f39bacf7c14d6cbbb720de84b5ccb0",
            "3686afaf63534510ace89a5f63e65449",
            "fd425766c3b144f689df9ca833f71e8c",
            "c5031bd007be476984fd5c696626f8db",
            "856e5f7a264744998b57d45fb5386308",
            "19b65bbea74f433d90d252c55932c417",
            "670641eee3574556b052114753f41f86",
            "7ea0d61a4fde49ff8826f54b8a1bcf92",
            "c345b1c90a634f308b9eed517a20cf40",
            "d3648f037ba04520982407dd7e9b69b6",
            "49e69ec61ec0449fa65321bb6f6855d7",
            "879ada31bd404d96a62d77b085f8553b",
            "2143027fb3544a31b07322487e341a7b",
            "c4f1197793ef497e8ab07a1743514bba",
            "4bef93481cc24b078ab892ad8f3af381",
            "6e5c190492a04a8582054d33e3505f72",
            "b3f7366837f341ea93469bc1c509c1ac",
            "95ce10fc94374870b9907c762b10e647",
            "feb1c249b27f4844985787846511a1cf",
            "bb372535aaab4f0dbb63a7206010960f",
            "df6af12432f641b8b3b949039db98873",
            "0c602d89802b450193f4efc9e0b4790d",
            "78c20bff3c544659b6319adb99dd6327",
            "410493abafed4e848338957c1d0ce8c4",
            "cd04aa1e3d9c4a75b9ee24d8c6b041b0",
            "9e044f2eed4a4fa48975b07f7e9e8879",
            "741b26c6db6540b5bc71a7980233b9d1",
            "5c0e4ae4383e470fbd0c8d9a59124045",
            "c2100bad82b047d4be3c06fd7cd3fbe1",
            "84697d4e3afe48c4ad8e7c148ee9add6",
            "988d6d61cc46416ab0066b027526e7bc",
            "986b7c3659414019bd2fd40f88cbf49b",
            "c660401c14de44ff969dad6f083c7ac3",
            "79838c1c9ac04fa18627ea969818cb97",
            "7c0475814a1b4bb9b4ca1723339689e8",
            "6b7be14128e54fd687ad64282f9ccea7",
            "4b11944ff8b5425da87465f9f01d8547",
            "d961455b1a2e4f30a40ec40c79f33278",
            "fcde77429f974493bcd885a381edeb5e",
            "e10e187879fa4b45b7a1867925685e9a",
            "01df746d601e49628c90afcdeb4de1d7",
            "1d52150fd8b44ff090680b32bad6c126",
            "82ba5f8059ad4b159ba1ccaf016b24a2",
            "3ff407910d174c52b9fd36a2b5daa41e",
            "37b8399f3f3f420d8c4c242a037814c8",
            "fa66099f89824f218f8642f386b0fde6",
            "6f22659ede70437a9fa2cae455334b64",
            "0d43b5a736f74da686892e75a368829c",
            "6908575c02e9492eb3477ab0763e28bb",
            "48a26fd28dbd4c698851d38d8c346b21",
            "469556173f8c4dff99136e4223fc69b3",
            "466fde2758c5460cb32845af7b1e5d39",
            "11ba3d74d1114db1a4681058f4d70440",
            "de27a71c01d54138926fc48059e0576e",
            "125a6ceaa6d34a5a81145e6448279462",
            "8430675afe2e4e05a066fad011a61f68",
            "c95aa38788dc4f129cb48be19c08e5df",
            "b1650e82e33f48c9a18fba0b8209a7b2",
            "fd418dcf0137450aa63f34e728b3199f",
            "ed08cbb12c864d37a83c990c37cc5618",
            "3844951cc2564f16a74ca9cec3b93b7e",
            "0c9ff89d083c4a768bdf52c734827082",
            "e6773e05c27c4870b3ad8387cdec3f6f",
            "e929a1af5a3d4aac895f3acd5364c39b",
            "57ebbfd5b6ab4b94ab7f1d714daf499d",
            "58d326cae5ea4dbb8442c54c8d37b72b",
            "9ba1e277b77340a6ae659475e6701b6f",
            "b85163d6fef54ccf815c6f79914ecd9f",
            "709636a091c5468b8fd17213d7a5e3f7",
            "5044e8e7418c4ca3a5c9059d91a85909",
            "b2907050905542e39bc1df03e471256c",
            "c7d99df395aa4a8fb099564a95abcf33",
            "9441cf5b45034389909ea5e34b03ae02",
            "44d4bfff8f2046b385cd338a306d2d6e",
            "30d46943ed7f40c9bb6e2c64be6477b9",
            "edf3f6363f794c9b8634a6be7ac6fb35",
            "8f070dac0bfc41f2b36830d4c31aaf88",
            "8c3bc5bb9b7949c9b16525bddcbcd18c",
            "2a65042b623245aa8d687a3e03827f18",
            "980a20825b254d50a41e52d32cfd02bc",
            "d723fb4def5d49a4abceb28a035c9823",
            "5e99e2a01e334f9cb75a7ac0a00ba403",
            "b8560d6d7d8045ad8e3923e239d08d07"
          ]
        },
        "id": "2W93muv_3s05",
        "outputId": "1bcec225-26d6-40c5-974d-7a441e48db89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee1a25e976a742d29a58b84802649ae0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f0ea70201c84434b0b0ac410422cb9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_hyena.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
            "- configuration_hyena.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a533929dc864acca00080e72dbb8b72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_hyena.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a38588c725aa44e8a701833820c59cbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "engine.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89251f6caa6741008fb8c6311392b378",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "utils.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
            "- utils.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
            "- engine.py\n",
            "- utils.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "308c11c21e624e6aa75d1632182cdb77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "layers.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
            "- layers.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d25283b4698945bfbb656701e2fa5a52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81109743f33441a18dd0520930ace72f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "positional_embeddings.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
            "- positional_embeddings.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7f2cfd706af40198d12972d31889af3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "cache.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
            "- cache.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "259c0663c3bb495aa577a646c36771f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
            "- tokenizer.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
            "- model.py\n",
            "- positional_embeddings.py\n",
            "- cache.py\n",
            "- tokenizer.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
            "- modeling_hyena.py\n",
            "- engine.py\n",
            "- layers.py\n",
            "- model.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "670641eee3574556b052114753f41f86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95ce10fc94374870b9907c762b10e647",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2100bad82b047d4be3c06fd7cd3fbe1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e10e187879fa4b45b7a1867925685e9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "469556173f8c4dff99136e4223fc69b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/3.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c9ff89d083c4a768bdf52c734827082",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9441cf5b45034389909ea5e34b03ae02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device: ', device)\n",
        "\n",
        "# Load pretrained base model\n",
        "model_config = AutoConfig.from_pretrained(model_name, trust_remote_code=True, revision=\"1.1_fix\")\n",
        "model_config.use_cache = False\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    config=model_config,\n",
        "    trust_remote_code=True,\n",
        "    revision=\"1.1_fix\",\n",
        "    device_map='auto',\n",
        "    torch_dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8002176beac3459585818798e1baab19",
            "a2519e584e1d45d38b2ace23ca92dfd3",
            "5d6cbc34a68d4bb6bbf8695770738e38",
            "5a689c7d7d634e7cbecd16630e6cb8ee",
            "63e4461743cb45ddb4b9b1b1d8cd229f",
            "f0b86abbffff494d940257c0b4ab1d28",
            "7cb61b1f426141ec91e7caa37b803e82",
            "cf9e0ed370cf474b9dd808142be33b3a",
            "26f0eb8526a247fe8e2b673513025a67",
            "beb8eb76d7174899b3a59cc2c9c99827",
            "7432c48b9e8144b5b1415f265eb65c92",
            "3eee3d6faf984ba9bc6d6d66c1a0dab7",
            "daac669971c64e03b7941d48fb6ee08c",
            "a5ac09722f75447280e7e9986ebb2ca8",
            "4a7968e4333047dda525b76e06d9c0d5",
            "cc9715e87593419cb3eafc4e401df827",
            "8c8690ecd3aa482e80b5d90ab1505606",
            "7dda595ede284f3ea09a25bf5bdd0904",
            "cc1a93e0b2134b78af4d8bd5682c1351",
            "59a91ca2976343e3ae92f902c6c16e1c",
            "93ae13c2adbb4d9ba544a53af76deeaa",
            "5c5a0d6973d44ff2852955b8e33e8033",
            "04abf2c393ff4892a0c87e2ec2ce659d",
            "277a63915faf4ed8a33b0016104414e2",
            "482fa4a11dd245afad0d13d8f5fda42e",
            "095138859797417a9f9ba81ed11c18c5",
            "4aa9ad9c643e4548b6da6afacf133b8c",
            "0a5c7d3aebd94053b23edf5adeae9b2a",
            "f78c105ee1654fb79facadc0cadb2b85",
            "3b1da8bd61374d9691b7b68b1407c490",
            "fff20cfcfd954d3393652d33fa89d39c",
            "28805ead7993472d8b12dc5cecb91f5c",
            "40f4a8257563474bb6cbc7c0284cf76d",
            "bf2540d4e3c14f59ab8f5b923e1eeab3",
            "6f240a918a3a4a10b9a8ab1d0bf2cc23",
            "356c666f037e4d1886e8fc84fa75814e",
            "f3ed75f9ebd5421caadd62e17107469f",
            "dce6f70da23e4403964b7fa3b780ea5a",
            "ba5e3bda39ea44c698dd907eddb6b503",
            "154af443090840b1b7a34c325b8fad2a",
            "c698fea902864ba48bf5c299658238f1",
            "4a52c99c88084fa89a6cbbf67d678442",
            "471d59092e0143a9b0423b94e32a2055",
            "745ed7c7f1794cd08d6b4427712a1f0b"
          ]
        },
        "id": "VvRLhLFJrubl",
        "outputId": "e7e07b08-b653-4c78-cbd2-819f2464eb3e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8002176beac3459585818798e1baab19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/299 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3eee3d6faf984ba9bc6d6d66c1a0dab7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing 'ATCGATCG'...\n",
            "Resulted token IDs (Evo is at single-nt resolution): tensor([[65, 84, 67, 71, 65, 84, 67, 71]])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04abf2c393ff4892a0c87e2ec2ce659d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6726 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf2540d4e3c14f59ab8f5b923e1eeab3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/748 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized dataset:\n",
            " DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 6726\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 748\n",
            "    })\n",
            "})\n",
            "trainable params: 17,829,888 || all params: 6,470,610,944 || trainable%: 0.2756\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiara725\u001b[0m (\u001b[33mkiara725-university-of-oxford\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250923_045858-93nb3rc4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kiara725-university-of-oxford/huggingface/runs/93nb3rc4' target=\"_blank\">elated-dawn-9</a></strong> to <a href='https://wandb.ai/kiara725-university-of-oxford/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/kiara725-university-of-oxford/huggingface' target=\"_blank\">https://wandb.ai/kiara725-university-of-oxford/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/kiara725-university-of-oxford/huggingface/runs/93nb3rc4' target=\"_blank\">https://wandb.ai/kiara725-university-of-oxford/huggingface/runs/93nb3rc4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2658' max='3364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2658/3364 55:56 < 14:52, 0.79 it/s, Epoch 3.16/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.565500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.551000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.545900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.524400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.509200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3364' max='3364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3364/3364 1:10:50, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.565500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.551000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.545900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.524400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.509200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.491200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed!!!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [187/187 00:46]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity after fine-tuning: 1.8105\n",
            "Fine-tuned model negative log-likelihood for 'ATCGATCG':  1.8316192626953125\n",
            "Likelihood: 0.1602%\n"
          ]
        }
      ],
      "source": [
        "# Section 3: LoRA fine-tuning of Evo-1\n",
        "# Only training a small proportion of parameters due to limited computational power...\n",
        "\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "print(\"Tokenizing 'ATCGATCG'...\")\n",
        "test_tokenize = tokenizer.encode('ATCGATCG', return_tensors='pt')\n",
        "print(f'Resulted token IDs (Evo is at single-nt resolution): {test_tokenize}') # [batch_size, n_tokens]\n",
        "\n",
        "tokenizer.pad_token = 'X'\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "def tokenize(example):  # always OOM... `max_length` set to super small now\n",
        "    return tokenizer(example['sequence'], max_length=512, padding=\"longest\", truncation=True)\n",
        "tokenized_dataset = split_dataset.map(tokenize,remove_columns=['sequence'])\n",
        "tokenized_dataset.set_format(type='torch')\n",
        "print('Tokenized dataset:\\n', tokenized_dataset)\n",
        "\n",
        "# Apply LoRA\n",
        "lora_config = LoraConfig(\n",
        "    task_type=None, # otherwise throws error since it would insert kwarg 'inputs_embeds' into the model's forward() method...\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias='none',\n",
        "    target_modules='all-linear')\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "lora_model.print_trainable_parameters()\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=1e-4,\n",
        "    save_total_limit=2,\n",
        "    bf16=True\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    data_collator=data_collator\n",
        ")\n",
        "print('Training...')\n",
        "trainer.train()\n",
        "print('Training completed!!!')\n",
        "\n",
        "# Save model\n",
        "lora_model.save_pretrained(\"./fine_tuned_evo\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_evo\")\n",
        "\n",
        "# Evaluate\n",
        "eval = trainer.evaluate()\n",
        "perplexity = math.exp(eval['eval_loss'])\n",
        "print(f'Perplexity after fine-tuning: {perplexity:.4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_loss = tokenizer('ATCGATCG', return_tensors='pt').input_ids.to(device)\n",
        "    loss = lora_model(test_loss, labels=test_loss).loss\n",
        "print(\"Fine-tuned model negative log-likelihood for 'ATCGATCG': \", loss.item())\n",
        "print(f'Likelihood: {math.exp(-loss.item()):.4f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyrFqkFN0PII"
      },
      "source": [
        "## The search for a better sequence...\n",
        "\n",
        "Trying to balance exploration and exploitation, and avoid enumerating by brute force...\n",
        "\n",
        "**Gradient-based sensitivity analysis**: by calculating the gradient of the model's loss w.r.t. each position on the current sequence, we can identify the nucleotides *where* mutations would most significantly impact the 'host-likeness' score (a small nudge can lead to greater changes). Rather than mutating positions randomly..., we leverage the model's knowledge to guide the search!\n",
        "\n",
        "(*Note that this idea isn't applicable with Evo-1 since its StripedHyena architecture doesn't support `inputs_embeds` *(input embeddings are needed since gradients can only flow through continuous tensors rather than discrete ids)* as a kwarg in the `forward()` method... Tried a few workarounds but didn't work as well (so sad). However, a demo of running this check via [Nucleotide Transformer](https://github.com/instadeepai/nucleotide-transformer) (which does support that kwarg; however, due to its way of tokenization, the performance for the check is very poor there...) can be seen directly below. For Evo-1, we'll just randomly propose positions to mutate...*)\n",
        "\n",
        "\n",
        "**Constrained MH-MCMC sampling**: once we've identified which positions to randomly mutate (*Monte Carlo*), we score the mutated sequence and use Metropolis criterion to decide whether to accept the mutation, and the iteration goes on autoregressively (*a Markov chain*). For those occurring in predefined regions (particularly the enzyme's active site), the new codon must be synonymous to be accepted. Codons that are swapped to stop codons are also automatically rejected.\n",
        "\n",
        "---\n",
        "\n",
        "References:\n",
        "- [1] https://github.com/arjan-hada/protein-variant-prediction/\n",
        "- [2] https://nrel.github.io/EvoProtGrad/getting_started/MCMC/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890,
          "referenced_widgets": [
            "27d3b96890ea40a0b6044eca10c182a9",
            "0b6e83f87f724efc8e5f3fa5258b1b10",
            "36453c9b9f27484b805a19974af9a7f7",
            "5b7644e16f0e43d3b707ff0a70e1e029",
            "d0166e69a2da48b4acff21f03a050296",
            "816ff5c1897643cd8bbdf3dcdc87bb6b",
            "f30874b314294c4cbb356c571d8b0665",
            "8677c64a21704811a2d3f88134135231",
            "1024329af0204e7d8b18c58d15f6eaf4",
            "644a749971054cf5bf519a38447ecefb",
            "7854a1dee20b421a8d38255293e8ecea",
            "9c9a387c26bb4778b01b72c000c2f4ed",
            "74096ef8bac14651b37fe72e9b63401c",
            "53220249e674451e8327399cc35d1329",
            "24336b1845b942aebedc704e7d4ffd7d",
            "03889111ca494b14989f6816b2750407",
            "a6510effe02b4aec8d7cc62d7a117880",
            "2bfe5dd1f8d2496dba9a24d99a63ae97",
            "534def21784c4c1089dedf36e8a4318b",
            "9c5b8688ded1429cbf0391749ab19e50",
            "7761840046fb421098c6b4a8646c2472",
            "f5ae04f4334e4ce289011fc59e4e613f",
            "60e31f04f0cf4d8eb248e5e73a336541",
            "1daa771b04be47b091b0f27497517186",
            "29b664ed71f9463da8f35abc6a636cc8",
            "15db7918031749afa93f66401960fbf7",
            "ef522d169af0447187eebd7587a8c0a6",
            "5f26c336b9344bee8b450359234dee93",
            "b2f9baece88d40c5960c394e49f32804",
            "c9b47be8023b4352a2393e391f7ceca3",
            "4762d17a06b24d6fac0ec2516a6c4358",
            "929fc8d7524843dfb195b07e8045f00d",
            "2ee0b6259de543b49ff0c22612c708ae",
            "f66bb72de5744ec5aab96c254f11c41c",
            "4aed9f7d55ad4d78b8021d1a52a5ff68",
            "5d61a510381942df863eb0dcdf227a89",
            "ba84bad1deee477bb48274fb1066bb97",
            "a264bb79e6ed45fc8f1e6e29f54141dc",
            "6ecc9915aa76487d92d64f85a046a78f",
            "29a838c219cb4485801f37818d6f373b",
            "1548bbf77d9e42d99dc3098275d77c6d",
            "87cbb42699944765ab7685b3c66e22a8",
            "46aef4856ae643b2a8042569295eff07",
            "4f719d9504894513be9e10edef3f2f3b",
            "15f63edcb96444a0bd05b5b78a7df381",
            "4f3c7d3cca704c9fb90c040e84ce4d77",
            "3ded20c1b47545829b9663896869de33",
            "7a3c41cebf294fe7a11a15ec2222dfbe",
            "a35832c60baa4efdae42da15a624bb31",
            "195f89635a6c4b5583fb34054d4fe14d",
            "bf9da47002854db8a191dcf6c39fa826",
            "61fd33ec54d04a9b8172267098fc7763",
            "1d15cd09d190494c91ea56bbf68b3240",
            "d26b99a157ec46b7a859c008460b4f3c",
            "69b306ec9e9b477480b18941b7972a22",
            "eb971e88b5c240948df177ac19f88890",
            "c0d3cf2474e34536a67bf992e68dc205",
            "bf954dfdf0a148169fd63436a3c1c512",
            "ec161acccc06458bb37cdb136c85784d",
            "b98a48acbb1a4a9580695df828396c84",
            "3d0e6d4af6124630b28c3291f4352394",
            "a1e20ce0aa004fa19dfde8d851e01816",
            "c7ec5107790c408bb92918388cbaad28",
            "01efca145f814733b7b533b02715fd10",
            "699500cadd66441990773c3e25f0adc0",
            "271448691aaa496d8ea070f82be10990",
            "a5c9f27adc6c42e888569a4dae5ee162",
            "11776bfe3d1248dd81dd1a516e7517eb",
            "64526529040b40f8bd0d4b03d0061259",
            "179a28bafa8b4bfe9f9a410e498ce44d",
            "f459cfa438364b7bbe661cb2272b1e52",
            "b8ce93d5d049485a88d47a7e3bae51a0",
            "1da34f97db614e649b3ec4d1e621ac3f",
            "1f048d301ef14130a3bf16b400d75d8b",
            "60a06dacfb19408e8d6e13411a464834",
            "a4db42e1321d4712b51e1e839471e0a0",
            "5622a73715434dddb6ffbfb7da45f54e"
          ]
        },
        "id": "srUjpWR8kIYM",
        "outputId": "93d0fc1b-d260-4a7b-9582-624743bcce27"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27d3b96890ea40a0b6044eca10c182a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c9a387c26bb4778b01b72c000c2f4ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60e31f04f0cf4d8eb248e5e73a336541",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f66bb72de5744ec5aab96c254f11c41c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15f63edcb96444a0bd05b5b78a7df381",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "esm_config.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species:\n",
            "- esm_config.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb971e88b5c240948df177ac19f88890",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_esm.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species:\n",
            "- modeling_esm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5c9f27adc6c42e888569a4dae5ee162",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/224M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial sequence length: 1227bp\n",
            "Number of tokens after tokenization (unlike Evo, Nucleotide Transformer is not tokenized per nt (6)): 208\n",
            "Input embeddings: tensor([[[ 1.1297,  0.3901,  0.5430,  ...,  0.5937, -0.6399, -1.0603],\n",
            "         [-0.4141, -1.3004,  0.2649,  ...,  0.7028, -0.1475, -0.0469],\n",
            "         [ 0.2986,  0.9750,  0.1171,  ..., -0.7686, -1.4304,  0.7572],\n",
            "         ...,\n",
            "         [ 0.1092,  0.2331,  0.0526,  ...,  0.3236,  1.2268, -1.5634],\n",
            "         [ 0.1460,  1.5183,  1.2592,  ...,  0.2580,  0.6456,  0.0566],\n",
            "         [ 1.1845, -0.5898,  0.0388,  ...,  0.5161,  0.7675, -0.6964]]],\n",
            "       device='cuda:0', grad_fn=<EmbeddingBackward0>)\n",
            "Shape of embeddings: torch.Size([1, 208, 512])\t[batch_size, n_tokens, dim]\n",
            "Gradients wrt token embeddings: tensor([[[-3.8040e-04,  1.7954e-03,  2.1245e-04,  ...,  5.2007e-04,\n",
            "          -2.7115e-04,  1.3895e-04],\n",
            "         [-2.2782e-05, -1.6707e-05, -2.0524e-04,  ...,  3.7162e-04,\n",
            "          -2.2162e-06,  2.4030e-04],\n",
            "         [ 3.4020e-04, -3.0065e-04,  1.0031e-04,  ...,  2.9150e-04,\n",
            "           3.7873e-05,  2.5692e-04],\n",
            "         ...,\n",
            "         [-4.8661e-05,  2.7047e-04, -1.3411e-03,  ...,  2.6976e-04,\n",
            "          -1.5239e-03, -5.9163e-04],\n",
            "         [-1.7596e-03,  8.8149e-04,  8.9536e-04,  ...,  8.0306e-04,\n",
            "          -8.1719e-04,  1.8525e-03],\n",
            "         [ 1.5201e-03, -5.5968e-04,  2.0609e-03,  ...,  1.4207e-03,\n",
            "           2.4007e-03, -2.9420e-03]]], device='cuda:0')\n",
            "Shape: torch.Size([1, 208, 512])\n",
            "\n",
            "Compute magnitudes of gradients wrt each token -> torch.Size([208])\n",
            "Indices of most sensitive tokens: [207 203 205]\n",
            "Tokenized initial sequence: ['<cls>', 'GTGTCG', 'ACGCAC', 'GTGAAC', 'TCGCAG', 'TCCGGG', 'CAGACA', 'CTCCCG', 'CCCGAG', 'CAGTGG', 'CGTGAC', 'AAGAAG', 'AGATAT', 'CTTTGG', 'CTGCTC', 'GGCCTG', 'GTGCCG', 'CCGACG', 'GCGGTC', 'TTCATT', 'GCCGTC', 'GGATTG', 'GTCGCG', 'TTGTTC', 'AACAGT', 'CTCGGG', 'TGGAAC', 'GCGGTC', 'TCGCCG', 'GTGTGG', 'TGGTGG', 'ATCGGG', 'CCGTTG', 'CTCGTC', 'TACATC', 'CTGCTC', 'CCGATC', 'CTCGAC', 'ATCTTC', 'TTCGGT', 'CCGGAC', 'GGCGAG', 'AATCCG', 'CCGGAC', 'GAGGTG', 'ATGGAG', 'CGCCTC', 'GAGAAC', 'GACAAG', 'TACTAC', 'CGGTAC', 'TGCACC', 'TACATC', 'TACATA', 'CCGTTC', 'CAGTTG', 'GCCAGC', 'CTGGTC', 'CTGGCC', 'TGCTAT', 'CTCTGG', 'TCGGCG', 'ACCGAC', 'CTGTCC', 'TGGCTC', 'GGAATC', 'GACGGG', 'GGACTG', 'GGGCTG', 'ATCTCC', 'AAGATC', 'GGTCTG', 'GCGATC', 'AGTATC', 'GGTTGC', 'GTCGCA', 'GGAATC', 'GGGATC', 'AACACC', 'GCACAC', 'GAACTA', 'GGTCAC', 'AAGAAG', 'GACGAT', 'CTCGAG', 'CGCTGG', 'TTGTCG', 'AAGATC', 'ACTCTG', 'GCGCAG', 'TCGTTT', 'TACGGC', 'CACTTC', 'TACATC', 'GAGCAC', 'AATCGT', 'GGACAC', 'CACGTG', 'CGGGTC', 'GCCACG', 'CCCGAG', 'GATCCG', 'GCGTCG', 'TCTCGC', 'TTCGGC', 'GAGAGC', 'TTCTGG', 'ACCTTC', 'CTGCCG', 'CGCAGT', 'GTGTGG', 'GGATCT', 'CTGCGC', 'TCGTCG', 'TGGTCC', 'CTGGAG', 'AAAGCC', 'AGGCTC', 'GATCGA', 'CTGGGT', 'AAGAAG', 'CCGTGG', 'ACAATT', 'CGCAAC', 'GACGTC', 'CTGCAT', 'TCGTGG', 'TTGATG', 'TCCGTC', 'GTACTC', 'TTCGGT', 'GTCCTC', 'GTCGCC', 'GTTTTC', 'GGGCTC', 'TCGGTG', 'CTGCCG', 'TTCCTG', 'GTGCTG', 'CAGGCC', 'GTCTTC', 'GGATTC', 'TGCCTG', 'CTCGAA', 'ACCGTC', 'AACTAC', 'CTCGAA', 'CATTAC', 'GGACTG', 'AAGCGT', 'CGCCGT', 'CTGGAC', 'AGTGGG', 'CGGTAC', 'GAGCGC', 'GCCGCA', 'CCGGAG', 'CACAGT', 'TGGAAC', 'AGCGAT', 'CACATC', 'TGCACC', 'AACATC', 'TTCCTG', 'TATCAC', 'CTCCAG', 'CGTCAC', 'AGTGAC', 'CATCAT', 'GCGAAC', 'CCGACA', 'CGTCGT', 'TATCAG', 'ACGCTT', 'CGAAGC', 'ATGGAC', 'CGTGCA', 'CCCAAC', 'CTGCCC', 'AGTGGA', 'TACGCG', 'AGCATG', 'ATCATG', 'CTCGCC', 'TACGTT', 'CCGCCG', 'CTGTGG', 'CGAAAA', 'GTAATG', 'GATCCC', 'AAGGTC', 'CTTGCG', 'CACTAC', 'GGCGGC', 'GACATC', 'ACCCGC', 'GTCAAC', 'GTTCAG', 'CCGTCC', 'AAGCGT', 'GATCGC', 'ATCCTT', 'GCTCGG', 'TACGGA', 'GCAGCG', 'T', 'G', 'A']\n",
            "Most sensitive spots on the initial sequence: ['A', 'TACGGA', 'T']\n",
            "(ahh- no wonder why these single-nt tokens in the end of the sequence are regarded as *most impactful* to the loss... so this 'sensitivity analysis' is pretty biased if the tokenization isn't done at single-nt resolution (Evo does though)...)\n"
          ]
        }
      ],
      "source": [
        "# Test the feasibility of the idea with Nucleotide Transformer, which does allow us to run backprop w.r.t. input embeddings\n",
        "!pip install --upgrade git+https://github.com/huggingface/transformers.git > /dev/null 2>&1\n",
        "from transformers import AutoModelForMaskedLM\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(\"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\", trust_remote_code=True)\n",
        "model2 = AutoModelForMaskedLM.from_pretrained(\"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\", trust_remote_code=True)\n",
        "model2.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def compute_sensitivity(sequence, model, tokenizer, top_k):\n",
        "    print(f'Initial sequence length: {len(sequence)}bp')\n",
        "    model.eval()\n",
        "    torch.set_grad_enabled(True)\n",
        "    input_ids = tokenizer.encode(sequence, return_tensors='pt').to(model.device)\n",
        "    print(f'Number of tokens after tokenization (unlike Evo, Nucleotide Transformer is not tokenized per nt (6)): {input_ids.shape[1]}') # [batch_size, n_tokens]\n",
        "    embeds = model.get_input_embeddings()(input_ids)  # **continuous** tensor for gradients to flow through\n",
        "    print(f'Input embeddings: {embeds}\\nShape of embeddings: {embeds.shape}\\t[batch_size, n_tokens, dim]')\n",
        "    embeds.retain_grad()\n",
        "    model.zero_grad()\n",
        "    outputs = model(inputs_embeds=embeds, labels=input_ids)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    grads = embeds.grad\n",
        "    print(f'Gradients wrt token embeddings: {grads}\\nShape: {grads.shape}')\n",
        "    norm = grads.norm(dim=-1).squeeze(0)\n",
        "    print(f'\\nCompute magnitudes of gradients wrt each token -> {norm.shape}')\n",
        "    top_pos = torch.topk(norm, top_k).indices # top-k instead of greedy search (choosing the largest position only) to be more exploratory\n",
        "    print(f'Indices of most sensitive tokens: {top_pos.cpu().numpy()}')\n",
        "    return top_pos.cpu().numpy()\n",
        "top_k = 3\n",
        "# Wild-type alkB sequence from original host species (Rhodococcus erythropolis strain XP; sequence extracted from NCBI)\n",
        "initial_seq = 'GTGTCGACGCACGTGAACTCGCAGTCCGGGCAGACACTCCCGCCCGAGCAGTGGCGTGACAAGAAGAGATATCTTTGGCTGCTCGGCCTGGTGCCGCCGACGGCGGTCTTCATTGCCGTCGGATTGGTCGCGTTGTTCAACAGTCTCGGGTGGAACGCGGTCTCGCCGGTGTGGTGGTGGATCGGGCCGTTGCTCGTCTACATCCTGCTCCCGATCCTCGACATCTTCTTCGGTCCGGACGGCGAGAATCCGCCGGACGAGGTGATGGAGCGCCTCGAGAACGACAAGTACTACCGGTACTGCACCTACATCTACATACCGTTCCAGTTGGCCAGCCTGGTCCTGGCCTGCTATCTCTGGTCGGCGACCGACCTGTCCTGGCTCGGAATCGACGGGGGACTGGGGCTGATCTCCAAGATCGGTCTGGCGATCAGTATCGGTTGCGTCGCAGGAATCGGGATCAACACCGCACACGAACTAGGTCACAAGAAGGACGATCTCGAGCGCTGGTTGTCGAAGATCACTCTGGCGCAGTCGTTTTACGGCCACTTCTACATCGAGCACAATCGTGGACACCACGTGCGGGTCGCCACGCCCGAGGATCCGGCGTCGTCTCGCTTCGGCGAGAGCTTCTGGACCTTCCTGCCGCGCAGTGTGTGGGGATCTCTGCGCTCGTCGTGGTCCCTGGAGAAAGCCAGGCTCGATCGACTGGGTAAGAAGCCGTGGACAATTCGCAACGACGTCCTGCATTCGTGGTTGATGTCCGTCGTACTCTTCGGTGTCCTCGTCGCCGTTTTCGGGCTCTCGGTGCTGCCGTTCCTGGTGCTGCAGGCCGTCTTCGGATTCTGCCTGCTCGAAACCGTCAACTACCTCGAACATTACGGACTGAAGCGTCGCCGTCTGGACAGTGGGCGGTACGAGCGCGCCGCACCGGAGCACAGTTGGAACAGCGATCACATCTGCACCAACATCTTCCTGTATCACCTCCAGCGTCACAGTGACCATCATGCGAACCCGACACGTCGTTATCAGACGCTTCGAAGCATGGACCGTGCACCCAACCTGCCCAGTGGATACGCGAGCATGATCATGCTCGCCTACGTTCCGCCGCTGTGGCGAAAAGTAATGGATCCCAAGGTCCTTGCGCACTACGGCGGCGACATCACCCGCGTCAACGTTCAGCCGTCCAAGCGTGATCGCATCCTTGCTCGGTACGGAGCAGCGTGA'\n",
        "sensitive_tokens = compute_sensitivity(initial_seq, model2, tokenizer2, top_k)\n",
        "tokens = tokenizer2.convert_ids_to_tokens(tokenizer2.encode(initial_seq))\n",
        "print(f'Tokenized initial sequence: {tokens}')\n",
        "print(f'Most sensitive spots on the initial sequence: {[tokens[i] for i in sensitive_tokens]}')\n",
        "print(\"(ahh- no wonder why these single-nt tokens in the end of the sequence are regarded as *most impactful* to the loss... so this 'sensitivity analysis' is pretty biased if the tokenization isn't done at single-nt resolution (Evo does though)...)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "01SgpLYcHjGO"
      },
      "outputs": [],
      "source": [
        "# Section 4: efficient 'mutagenesis' on candidate sequence\n",
        "\n",
        "\n",
        "# Run gradient-based sensitivity analysis\n",
        "\n",
        "# def compute_sensitivity(sequence, model, tokenizer, top_k):\n",
        "#     model.eval()\n",
        "#     torch.set_grad_enabled(True)\n",
        "#     input_ids = tokenizer.encode(sequence, return_tensors='pt').to(model.device) # discrete token ids\n",
        "#     embeds = model.get_input_embeddings()(input_ids)  # continuous tensor for gradients to flow through\n",
        "#     embeds.retain_grad()\n",
        "#     model.zero_grad()\n",
        "#     outputs = model(inputs_embeds=embeds, labels=input_ids)\n",
        "#     loss = outputs.loss\n",
        "#     loss.backward()\n",
        "#     grads = embeds.grad.norm(dim=-1).squeeze(0)  # get magnitudes of gradients for each token\n",
        "#     top_pos = torch.topk(grads, top_k).indices  # top-k instead of greedy search (choosing the largest position only) to be more exploratory\n",
        "#     print(top_pos)\n",
        "#     return top_pos.cpu().numpy()\n",
        "\n",
        "# Couldn't work on Evo-1 since its StripedHyena architecture doesn't support inputs_embeds as a kwarg in its forward() method... sad\n",
        "# Tried a few workarounds but didn't work as well.\n",
        "# For Evo-1, we'll just randomly propose positions to mutate...\n",
        "def a_compromise(sequence, model, tokenizer, top_k):\n",
        "    input_ids = tokenizer.encode(sequence, return_tensors='pt').to(model.device)\n",
        "    seq_len = input_ids.size(1)\n",
        "    top_k = min(top_k, seq_len)\n",
        "    positions = random.sample(range(seq_len), top_k)  # now it's just random... sad...\n",
        "    return positions\n",
        "\n",
        "# Score candidate sequence using fine-tuned model (-> reflects 'host-likeness')\n",
        "\n",
        "# The improvement on point mutations is far too small... by manually summing rather than averaging (as in `.loss()`) this would hopefully magnify the difference a bit...\n",
        "def score_sequence(seq, model, tokenizer):\n",
        "    tokens = tokenizer.encode(seq, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens, labels=tokens)\n",
        "        logits = outputs.logits\n",
        "    shift_logits = logits[:, :-1, :].contiguous()\n",
        "    shift_labels = tokens[:, 1:].contiguous()\n",
        "    logprobs = F.log_softmax(shift_logits, dim=-1)\n",
        "    token_logprobs = logprobs.gather(dim=-1, index=shift_labels.unsqueeze(-1)).squeeze(-1)  # shape [1, L-1]\n",
        "    total = token_logprobs.sum().item()\n",
        "    return total\n",
        "\n",
        "# Iterative MCMC sampling with Metropolis criterion while preserving active site and rejecting nonsense mutations\n",
        "def mcmc(seq, model, iterations, temp, tokenizer, protected_positions):\n",
        "    current_seq = seq\n",
        "    current_score = score_sequence(current_seq, model, tokenizer)\n",
        "    best_seq = current_seq\n",
        "    best_score = current_score\n",
        "    for iter in range(iterations):\n",
        "        # Get sensitive positions based on current sequence\n",
        "        # No - set to randomly sample positions now\n",
        "        # sensitive_pos = compute_sensitivity(current_seq, model, tokenizer, 3)\n",
        "        selected_pos = a_compromise(current_seq, model, tokenizer, 3)\n",
        "        # Randomly select one of these positions to mutate\n",
        "        pos = np.random.choice(selected_pos)\n",
        "        current_base = current_seq[pos]\n",
        "        possible_bases = [base for base in ['A', 'C', 'G', 'T'] if base != current_base]\n",
        "        new_base = np.random.choice(possible_bases)\n",
        "        new_seq = current_seq[:pos] + new_base + current_seq[pos+1:]\n",
        "        # Check if missense mutation occurs in functional site or if nonsense mutation occurs\n",
        "        codon_start = (pos // 3) * 3\n",
        "        old_codon = current_seq[codon_start:codon_start+3]\n",
        "        new_codon = new_seq[codon_start:codon_start+3]\n",
        "        if len(new_codon) == 3:\n",
        "            old_aa = str(Seq(old_codon).translate())\n",
        "            new_aa = str(Seq(new_codon).translate())\n",
        "            # 1. Active site preservation: reject missense and continue to next iteration\n",
        "            if codon_start in protected_positions and old_aa != new_aa:\n",
        "                continue\n",
        "            # 2. Reject nonsense mutations\n",
        "            if new_aa == \"*\":   # a stop codon\n",
        "                continue\n",
        "        # Score the new sequence\n",
        "        new_score = score_sequence(new_seq, model, tokenizer)\n",
        "        # Accept the move based on Metropolis criterion\n",
        "        delta = new_score - current_score\n",
        "        if delta > 0 or np.random.rand() < math.exp(delta / temp):\n",
        "            current_seq = new_seq\n",
        "            current_score = new_score\n",
        "            if best_score < new_score:\n",
        "                best_seq = new_seq\n",
        "                best_score = new_score\n",
        "    return {\n",
        "    'best_seq': best_seq,\n",
        "    'best_score': best_score,\n",
        "    'final_seq': current_seq,\n",
        "    'final_score': current_score}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "195CqrcnATRE",
        "outputId": "f592c369-702c-4ade-9587-486287949258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSTHVNSQSGQTLPPEQWRDKKRYLWLLGLVPPTAVFIAVGLVALFNSLGWNAVSPVWWWIGPLLVYILLPILDIFFGPDGENPPDEVMERLENDKYYRYCTYIYIPFQLASLVLACYLWSATDLSWLGIDGGLGLISKIGLAISIGCVAGIGINTAHELGHKKDDLERWLSKITLAQSFYGHFYIEHNRGHHVRVATPEDPASSRFGESFWTFLPRSVWGSLRSSWSLEKARLDRLGKKPWTIRNDVLHSWLMSVVLFGVLVAVFGLSVLPFLVLQAVFGFCLLETVNYLEHYGLKRRRLDSGRYERAAPEHSWNSDHICTNIFLYHLQRHSDHHANPTRRYQTLRSMDRAPNLPSGYASMIMLAYVPPLWRKVMDPKVLAHYGGDITRVNVQPSKRDRILARYGAA\n",
            "Conserved motif:  HSDHH  (missense mutations not allowed)\n",
            "Protected positions on coding DNA sequence: ['C', 'A', 'C', 'C', 'A', 'T', 'C', 'A', 'T']\n",
            "==================================================\n",
            "Optimizing gene sequence...\n",
            "Initial sequence score:  -672.0\n",
            "                                            best_seq  best_score  \\\n",
            "0  TTGTCGACGCACGTGAACTCGCAGTCCGCGCAGTCACTCCCGCCCG... -611.961487   \n",
            "1  ATGTCGACTCACGTGAACCCGCAGACCGGGCAGGCACTTCCGCCCG... -609.123840   \n",
            "2  GTGTCGACGCACGTGAACTCGCAGTCCGCGCAGTCACTTCCGGCCG... -619.865540   \n",
            "3  ATGTCGACGATCGTGACCCCGCCGTCCGGGCAGACCATCCCGCCCG... -586.281982   \n",
            "4  GTGTCGACGAACGTGAACTCGCAGTCCGGGCAGACACTCCCGCCCG... -594.338440   \n",
            "\n",
            "                                           final_seq  final_score  \n",
            "0  TTGTCGACGCACGTGAACTCGCAGTCCGCGCAGTCACTCCCGCCCG...  -612.237671  \n",
            "1  ATGTCGACTCACGTGAACCCGCAGACCGGGCAGGCACTTCCGCCCG...  -609.123840  \n",
            "2  GTGTCGACGCACGTGAACTCGCAGTCCGCGCAGTCACTTCCGGCCG...  -619.865540  \n",
            "3  ATGTCGACGATCGTGACCCCGCCGTCCGGGCAGACCATCCCGCCCG...  -586.281982  \n",
            "4  GTGTCGACGAACGTGAACTCGCAGTCCGGGCAGACACTCCCGCCCG...  -594.338440  \n",
            "MSTHVNSQSAQSLPPEQWRDKKRYLWLLGLVPPTAIFIAFGVVALFDSLGWNAVSPVWWWIGPMLVYILLPILDIFFGPDGENPPDEVMEHLENDKYYRYCTYIYIPFQLASLVLACYLWSASDLSWLGIDGGLGLVSKIGLAISVGCIAGIGINTAHELGHKKDDLERWLSKITLAQSFYGHFYIEHNRGHHVRVATPEDPASSRFGESFWSFLPRSVWGSLRSAWSLEKTRLDRLGKKPWTIRNDVLNSWLMSVVLFGVLFAVFGLPVLPFLLLQAVFGFCLLETVNYLEHYGLQRRRLDSGRYERAAPEHSWNSDHICTNIFLYHLQRHSDHHANPTRRYQTLRSMDRAPNLPSGYASMIMLAYVPPLWRKVMDPRVLEHYGGDITRANVQPSKRDRILARYGAA\n",
            "MSTHVNPQTGQALPPEQWRDKKRYLWLLGLVPPTAVFIAVGVVSVFNSLGWNVFAPVWWWIGPLLVYILLPILDVFFGPDGENPPDEVMEHLEDDKYYRYCTYIYIPFQFASLVLACYLWSATDLSWLGIDGGLGLVSKIGLAISIGCVAGIGINTAHELGHKKDDLERWLSKITLAQTFYGHFYIEHNRGHHVRVATPEDPASSRFGESFWSFLPRSVWGSLRSSWSLEKARLGRLGKKPWTIRNDVLHSWLMSVVLFGALVAVFGLAVLPFLVLQAVFGFSLLETVNYLEHYGLQRRRLDSGRYERATPAHSWNSDHICTNIFLYHLQRHSDHHANPTRRYQTLRSMDRAPNLPSGYASMILLAYVPPLWRKVMDPKVLAHYGGDITRVNVQPSKRERILARYGAA\n",
            "MSTHVNSQSAQSLPAEQWRDKKRYLWLLGLVPPTAVFLAVGLVALLNSLGWSAASPVWWWIGPLLVYILLPILDIFFGPDGENPPDEVMERLENDKYYRYCTYIYIPFQFASLVVACYLWSATDLSWLGIDGGLGLISKIGLAISIGCFAGIGINTAHELGHKKDDLERWLSKITLAQSFYGHFYIEHNRGHHVRVATPEDPASSRFGESFWTFLPRSVWGSLRSSWSLEKARIDRLGKKPWTIRNDVLHSWLMSVVLFGALVAVFGPAVLPFLVLQAVFGFSLLETVNYLEHYGLKRRRLDSGRYERAEPAHSWNSDHICTNIFLYHLQRHSDHHANPTRRYQTLRSMDRAPNLPSGYASMITLAYVPPLWRKVMDPKVVAHYGGDITRANVQPSKRERILARYGAA\n",
            "MSTIVTPPSGQTIPPEQWRDKKRYLWLLGLVPPTAVFLALGLVALLNSLGWNVVAPVWWWIGPMLVYILIPILDIFFGPDGENPPDEVMERLENDKYYRYCTYIYIPFQFASLVLACYLWSATDLSWLGIDGGLGLISKIGLAISVGCIAGIGINTAHELGHKKDDLERWLSKITLAQSFYGHFYIEHNRGHHVRVATPEDPASSRFGESFWSFLPRSVWGSLRSSWSLEKARLARLGKKPWTFRNDVLNSWLMSVVLFGALIAVFGVAVLPFLVLQAVFGFSLLETVNYLEHYGLKRRRLDSGRYERAEPAHSWNSDHICTNIFLYHLQRHSDHHANPTRRYQTLRSMEGAPNLPSGYASMIMLAYVPPLWRKVMDPKVLAHYDGDITRVNVQPSKRERILARYGAE\n",
            "MSTNVNSQSGQTLPPEQWRDKKRYLWLIGLVPPTAVFVAVGLVWWLNSLGWNTVSPVWWWIGPLLVYVLIPILDIFFGPDGENPPDEVMELLENDKYYRYCTYIYIPFQLASLILACYLWSATDLSWLGIDGGLGLVSKIGLAISIGCIAGIGINTAHELGHKKDDLERWLSKITLAQTFYGHFYIEHNRGHHVRVATPEDPASSRFGESFWRFLPRSVWGSLRSSWGLEKARLDRLGKKPWTIHNDVLHSWLMSVVLFGGLVAVFGISVLPFLVLQAVFGFCLLETVNYLEHYGLKRRRLDSGRYERAEPEHSWNSDHLCTNIFLYHLQRHSDHHANPTRRYQTLRSMDRAPNLPSGYASMIMLAYFPPLWRKVMDPKVLAHYDGDITRVNVQPSKRDRILARYGAA\n"
          ]
        }
      ],
      "source": [
        "# Section 5: target sequence optimization (finally)\n",
        "\n",
        "# Wild-type alkB sequence from original host species (Rhodococcus erythropolis strain XP; sequence extracted from NCBI)\n",
        "initial_seq = 'GTGTCGACGCACGTGAACTCGCAGTCCGGGCAGACACTCCCGCCCGAGCAGTGGCGTGACAAGAAGAGATATCTTTGGCTGCTCGGCCTGGTGCCGCCGACGGCGGTCTTCATTGCCGTCGGATTGGTCGCGTTGTTCAACAGTCTCGGGTGGAACGCGGTCTCGCCGGTGTGGTGGTGGATCGGGCCGTTGCTCGTCTACATCCTGCTCCCGATCCTCGACATCTTCTTCGGTCCGGACGGCGAGAATCCGCCGGACGAGGTGATGGAGCGCCTCGAGAACGACAAGTACTACCGGTACTGCACCTACATCTACATACCGTTCCAGTTGGCCAGCCTGGTCCTGGCCTGCTATCTCTGGTCGGCGACCGACCTGTCCTGGCTCGGAATCGACGGGGGACTGGGGCTGATCTCCAAGATCGGTCTGGCGATCAGTATCGGTTGCGTCGCAGGAATCGGGATCAACACCGCACACGAACTAGGTCACAAGAAGGACGATCTCGAGCGCTGGTTGTCGAAGATCACTCTGGCGCAGTCGTTTTACGGCCACTTCTACATCGAGCACAATCGTGGACACCACGTGCGGGTCGCCACGCCCGAGGATCCGGCGTCGTCTCGCTTCGGCGAGAGCTTCTGGACCTTCCTGCCGCGCAGTGTGTGGGGATCTCTGCGCTCGTCGTGGTCCCTGGAGAAAGCCAGGCTCGATCGACTGGGTAAGAAGCCGTGGACAATTCGCAACGACGTCCTGCATTCGTGGTTGATGTCCGTCGTACTCTTCGGTGTCCTCGTCGCCGTTTTCGGGCTCTCGGTGCTGCCGTTCCTGGTGCTGCAGGCCGTCTTCGGATTCTGCCTGCTCGAAACCGTCAACTACCTCGAACATTACGGACTGAAGCGTCGCCGTCTGGACAGTGGGCGGTACGAGCGCGCCGCACCGGAGCACAGTTGGAACAGCGATCACATCTGCACCAACATCTTCCTGTATCACCTCCAGCGTCACAGTGACCATCATGCGAACCCGACACGTCGTTATCAGACGCTTCGAAGCATGGACCGTGCACCCAACCTGCCCAGTGGATACGCGAGCATGATCATGCTCGCCTACGTTCCGCCGCTGTGGCGAAAAGTAATGGATCCCAAGGTCCTTGCGCACTACGGCGGCGACATCACCCGCGTCAACGTTCAGCCGTCCAAGCGTGATCGCATCCTTGCTCGGTACGGAGCAGCGTGA'\n",
        "\n",
        "# Note that, 'the triplet GTG was found to be the alkB gene start codon, which is typical of the genetic code of Rhodococcus strains' (http://dx.doi.org/10.1128/AEM.01987-10)\n",
        "# However, the ribosome still recognizes it and recruits tRNA^fMet, so the first AA should be M rather than V\n",
        "\n",
        "# Translate the CDS into protein sequence\n",
        "from Bio.Seq import Seq\n",
        "initial_pr = str(Seq(initial_seq).translate(table=\"Bacterial\", cds=True)) # for non-standard start codons (https://biopython-tutorial.readthedocs.io/en/latest/notebooks/03%20-%20Sequence%20Objects.html)\n",
        "print(initial_pr)\n",
        "\n",
        "# Potential conserved amino acid residues of the enzyme (only for illustrative purposes in this demo)\n",
        "his_pos = [331, 334, 335]  # indices for histidine residues in the conserved HSDHH motif of AlkB; 0-based\n",
        "print('Conserved motif: ',initial_pr[331:336],' (missense mutations not allowed)')\n",
        "# Convert to indices for nucleotides\n",
        "protected_positions = []\n",
        "for his in his_pos:\n",
        "    start_nt = his * 3\n",
        "    protected_positions.extend([start_nt, start_nt + 1, start_nt + 2])\n",
        "print('Protected positions on coding DNA sequence:',\n",
        "      [initial_seq[pos] for pos in protected_positions])\n",
        "\n",
        "print('='*50)\n",
        "print('Optimizing gene sequence...')\n",
        "init_score = score_sequence(initial_seq, model, tokenizer)\n",
        "print('Initial sequence score: ', init_score)\n",
        "\n",
        "# Sequentially run MCMC chains for more than one sampled sequence\n",
        "# (I first tried Dask for parallelization...)\n",
        "num_chains = 5\n",
        "results = []\n",
        "for i in range(num_chains):\n",
        "    results.append(mcmc(initial_seq, model=lora_model, iterations=1000, temp=0.2, tokenizer=tokenizer, protected_positions=protected_positions))\n",
        "optimized_sequences = pd.DataFrame(results)\n",
        "print(optimized_sequences)\n",
        "optimized_sequences.to_csv('optimized_seq.csv', index=False)\n",
        "with open('/optimized_pr.csv', 'w') as f:\n",
        "    for i, seq in enumerate(optimized_sequences['best_seq']):\n",
        "        pr = Seq(seq).translate(table=\"Bacterial\", cds=True)\n",
        "        print(pr)\n",
        "        f.write(f'>optimized_{i}\\n{pr}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "VBAN0tnuhHCj",
        "outputId": "5c2b4ade-5de9-4c65-c4f1-f0299ee31dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CAI (Codon Adaptation Index) is a measurement of the relative adaptiveness of the codon usage of a gene towards the codon usage of highly expressed genes. Its values range from 0 (low) to 1 (high).\n",
            "GC Content of the initial sequence: 0.6055419722901385\n",
            "Substitutions in seq_1: [(0, 'T', 'G'), (28, 'C', 'G'), (33, 'T', 'A'), (74, 'C', 'T'), (105, 'A', 'G'), (117, 'T', 'G'), (122, 'C', 'A'), (123, 'G', 'T'), (138, 'G', 'A'), (158, 'A', 'G'), (189, 'A', 'T'), (242, 'T', 'C'), (248, 'C', 'T'), (254, 'C', 'G'), (271, 'A', 'G'), (327, 'C', 'T'), (353, 'C', 'T'), (367, 'G', 'C'), (386, 'C', 'A'), (408, 'G', 'A'), (435, 'G', 'A'), (440, 'C', 'T'), (444, 'A', 'G'), (479, 'T', 'A'), (510, 'C', 'T'), (569, 'G', 'T'), (572, 'C', 'A'), (581, 'C', 'G'), (596, 'G', 'C'), (614, 'C', 'T'), (623, 'T', 'C'), (637, 'G', 'C'), (638, 'T', 'C'), (665, 'G', 'T'), (671, 'G', 'C'), (675, 'G', 'T'), (677, 'C', 'G'), (683, 'G', 'C'), (693, 'A', 'G'), (713, 'C', 'T'), (747, 'A', 'C'), (764, 'G', 'C'), (785, 'G', 'C'), (786, 'T', 'G'), (794, 'G', 'T'), (804, 'C', 'T'), (822, 'C', 'G'), (824, 'T', 'G'), (857, 'G', 'A'), (884, 'C', 'A'), (888, 'C', 'A'), (899, 'G', 'T'), (923, 'T', 'C'), (929, 'G', 'A'), (980, 'C', 'T'), (1007, 'C', 'T'), (1028, 'C', 'T'), (1058, 'G', 'C'), (1073, 'G', 'A'), (1100, 'T', 'C'), (1118, 'G', 'A'), (1124, 'T', 'A'), (1130, 'C', 'T'), (1135, 'G', 'A'), (1139, 'T', 'C'), (1142, 'C', 'T'), (1144, 'A', 'C'), (1171, 'C', 'T'), (1178, 'C', 'T'), (1196, 'C', 'T')]\n",
            "Substitutions in seq_2: [(0, 'A', 'G'), (8, 'T', 'G'), (18, 'C', 'T'), (24, 'A', 'T'), (33, 'G', 'A'), (38, 'T', 'C'), (86, 'A', 'C'), (104, 'C', 'G'), (123, 'G', 'T'), (129, 'T', 'G'), (132, 'G', 'T'), (149, 'A', 'G'), (157, 'T', 'C'), (159, 'T', 'G'), (162, 'G', 'T'), (194, 'G', 'C'), (209, 'G', 'C'), (222, 'G', 'A'), (236, 'C', 'G'), (248, 'C', 'T'), (271, 'A', 'G'), (279, 'G', 'A'), (317, 'C', 'A'), (329, 'C', 'G'), (341, 'G', 'C'), (386, 'G', 'A'), (408, 'G', 'A'), (452, 'G', 'A'), (534, 'A', 'T'), (566, 'C', 'T'), (572, 'G', 'A'), (614, 'C', 'T'), (636, 'T', 'A'), (653, 'C', 'T'), (662, 'T', 'A'), (703, 'G', 'A'), (704, 'C', 'T'), (781, 'C', 'T'), (794, 'G', 'T'), (800, 'A', 'G'), (804, 'G', 'T'), (846, 'A', 'T'), (878, 'C', 'T'), (888, 'C', 'A'), (911, 'A', 'G'), (914, 'C', 'G'), (927, 'A', 'G'), (934, 'C', 'A'), (992, 'C', 'T'), (1001, 'T', 'C'), (1007, 'C', 'T'), (1025, 'C', 'T'), (1034, 'C', 'G'), (1052, 'G', 'T'), (1055, 'G', 'A'), (1058, 'G', 'C'), (1073, 'C', 'A'), (1089, 'C', 'A'), (1103, 'C', 'T'), (1130, 'C', 'T'), (1133, 'G', 'C'), (1142, 'C', 'T'), (1196, 'A', 'T'), (1208, 'C', 'T')]\n",
            "Substitutions in seq_3: [(28, 'C', 'G'), (33, 'T', 'A'), (38, 'T', 'C'), (42, 'G', 'C'), (111, 'C', 'A'), (135, 'C', 'T'), (154, 'G', 'A'), (160, 'C', 'T'), (185, 'A', 'G'), (209, 'G', 'C'), (329, 'C', 'G'), (342, 'G', 'C'), (347, 'G', 'C'), (383, 'G', 'C'), (405, 'T', 'C'), (422, 'C', 'T'), (444, 'T', 'G'), (479, 'G', 'A'), (497, 'C', 'T'), (572, 'C', 'A'), (596, 'G', 'C'), (614, 'A', 'T'), (617, 'G', 'C'), (665, 'C', 'T'), (696, 'C', 'A'), (699, 'A', 'C'), (713, 'G', 'T'), (756, 'C', 'T'), (773, 'G', 'C'), (781, 'C', 'T'), (794, 'C', 'T'), (802, 'C', 'T'), (804, 'G', 'T'), (833, 'A', 'C'), (847, 'C', 'G'), (848, 'A', 'C'), (884, 'T', 'A'), (899, 'G', 'T'), (911, 'C', 'G'), (928, 'A', 'C'), (929, 'G', 'A'), (934, 'C', 'A'), (992, 'G', 'T'), (1040, 'G', 'A'), (1090, 'C', 'T'), (1124, 'T', 'A'), (1140, 'G', 'C'), (1171, 'C', 'T'), (1196, 'G', 'T'), (1208, 'C', 'T')]\n",
            "Substitutions in seq_4: [(0, 'A', 'G'), (9, 'A', 'C'), (10, 'T', 'A'), (16, 'C', 'A'), (18, 'C', 'T'), (22, 'C', 'A'), (35, 'C', 'A'), (36, 'A', 'C'), (107, 'G', 'C'), (111, 'C', 'A'), (117, 'C', 'G'), (131, 'C', 'G'), (135, 'C', 'T'), (157, 'T', 'C'), (162, 'G', 'T'), (164, 'A', 'G'), (189, 'A', 'T'), (207, 'A', 'C'), (236, 'C', 'G'), (242, 'T', 'C'), (248, 'C', 'T'), (317, 'C', 'A'), (329, 'C', 'G'), (383, 'G', 'C'), (413, 'G', 'C'), (435, 'G', 'A'), (440, 'C', 'T'), (444, 'A', 'G'), (449, 'C', 'A'), (458, 'C', 'G'), (510, 'C', 'T'), (566, 'C', 'T'), (587, 'G', 'C'), (590, 'G', 'C'), (614, 'C', 'T'), (617, 'T', 'C'), (623, 'T', 'C'), (636, 'T', 'A'), (683, 'G', 'C'), (703, 'C', 'A'), (713, 'C', 'T'), (728, 'C', 'A'), (729, 'T', 'A'), (747, 'A', 'C'), (764, 'G', 'C'), (773, 'G', 'C'), (781, 'C', 'T'), (782, 'G', 'C'), (786, 'A', 'G'), (794, 'G', 'T'), (800, 'C', 'G'), (801, 'G', 'C'), (803, 'G', 'C'), (804, 'G', 'T'), (846, 'A', 'T'), (885, 'T', 'C'), (896, 'T', 'C'), (902, 'C', 'G'), (911, 'T', 'G'), (914, 'T', 'G'), (928, 'A', 'C'), (929, 'G', 'A'), (934, 'C', 'A'), (953, 'C', 'T'), (1001, 'T', 'C'), (1004, 'C', 'T'), (1013, 'T', 'C'), (1028, 'C', 'T'), (1040, 'G', 'A'), (1049, 'G', 'C'), (1050, 'G', 'C'), (1055, 'G', 'A'), (1097, 'G', 'C'), (1118, 'C', 'A'), (1124, 'T', 'A'), (1139, 'G', 'C'), (1153, 'A', 'G'), (1196, 'G', 'T'), (1205, 'G', 'T'), (1211, 'A', 'G'), (1220, 'C', 'A'), (1222, 'A', 'C')]\n",
            "Substitutions in seq_5: [(9, 'A', 'C'), (71, 'C', 'T'), (74, 'C', 'T'), (81, 'A', 'C'), (111, 'G', 'A'), (122, 'G', 'A'), (129, 'T', 'G'), (130, 'G', 'C'), (133, 'G', 'T'), (137, 'G', 'C'), (143, 'C', 'T'), (149, 'A', 'G'), (156, 'A', 'G'), (158, 'C', 'G'), (185, 'A', 'G'), (194, 'G', 'C'), (201, 'G', 'A'), (207, 'A', 'C'), (236, 'C', 'G'), (271, 'T', 'G'), (317, 'T', 'A'), (339, 'A', 'G'), (386, 'T', 'A'), (405, 'T', 'C'), (408, 'G', 'A'), (440, 'C', 'T'), (444, 'A', 'G'), (449, 'G', 'A'), (458, 'C', 'G'), (479, 'G', 'A'), (534, 'A', 'T'), (572, 'T', 'A'), (614, 'G', 'T'), (629, 'T', 'C'), (637, 'G', 'C'), (638, 'G', 'C'), (656, 'C', 'G'), (662, 'T', 'A'), (665, 'A', 'T'), (681, 'G', 'T'), (682, 'G', 'C'), (713, 'C', 'T'), (733, 'A', 'G'), (764, 'G', 'C'), (767, 'G', 'C'), (770, 'C', 'A'), (781, 'G', 'T'), (785, 'G', 'C'), (794, 'C', 'T'), (800, 'C', 'G'), (801, 'A', 'C'), (836, 'G', 'C'), (842, 'T', 'A'), (875, 'G', 'A'), (896, 'A', 'C'), (899, 'A', 'T'), (911, 'T', 'G'), (928, 'A', 'C'), (957, 'C', 'A'), (980, 'C', 'T'), (1019, 'C', 'A'), (1040, 'G', 'A'), (1043, 'T', 'C'), (1070, 'C', 'T'), (1101, 'T', 'G'), (1124, 'G', 'A'), (1133, 'G', 'C'), (1142, 'G', 'T'), (1148, 'T', 'C'), (1153, 'A', 'G'), (1205, 'G', 'T'), (1208, 'C', 'T')]\n",
            "  sequence_id       CAI  GC_content\n",
            "0       opt_1  0.611701   62.102689\n",
            "1       opt_2  0.609561   62.347188\n",
            "2       opt_3  0.586947   61.939690\n",
            "3       opt_4  0.596624   61.369193\n",
            "4       opt_5  0.599575   61.043195\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Section 6: validation of obtained optimized sequences - compatibility with the host species\n",
        "\n",
        "\n",
        "# Kazusa codon usage table for Streptomyces lividans:\n",
        "# http://www.kazusa.or.jp/codon/cgi-bin/showcodon.cgi?species=1916\n",
        "\n",
        "print('CAI (Codon Adaptation Index) is a measurement of the relative adaptiveness of the codon usage of a gene towards the codon usage of highly expressed genes. Its values range from 0 (low) to 1 (high).')\n",
        "\n",
        "codon_usage = {\n",
        "    \"UUU\":0.9, \"UUC\":24.5, \"UUA\":0.2, \"UUG\":3.5,\n",
        "    \"UCU\":1.6, \"UCC\":19.7, \"UCA\":2.0, \"UCG\":13.7,\n",
        "    \"UAU\":1.2, \"UAC\":18.9, \"UAA\":0.3, \"UAG\":0.6,\n",
        "    \"UGU\":1.0, \"UGC\":8.8, \"UGA\":2.4, \"UGG\":15.3,\n",
        "    \"CUU\":3.1, \"CUC\":34.3, \"CUA\":0.9, \"CUG\":53.8,\n",
        "    \"CCU\":3.4, \"CCC\":24.8, \"CCA\":2.5, \"CCG\":30.1,\n",
        "    \"CAU\":2.3, \"CAC\":19.1, \"CAA\":2.8, \"CAG\":32.4,\n",
        "    \"CGU\":6.9, \"CGC\":39.7, \"CGA\":4.7, \"CGG\":26.1,\n",
        "    \"AUU\":2.0, \"AUC\":31.4, \"AUA\":0.9, \"AUG\":17.2,\n",
        "    \"ACU\":2.4, \"ACC\":37.7, \"ACA\":3.2, \"ACG\":19.8,\n",
        "    \"AAU\":1.4, \"AAC\":17.0, \"AAA\":2.9, \"AAG\":27.1,\n",
        "    \"AGU\":2.3, \"AGC\":14.6, \"AGA\":1.1, \"AGG\":4.0,\n",
        "    \"GUU\":2.8, \"GUC\":42.1, \"GUA\":3.5, \"GUG\":28.4,\n",
        "    \"GCU\":7.2, \"GCC\":71.0, \"GCA\":11.0, \"GCG\":43.5,\n",
        "    \"GAU\":4.7, \"GAC\":55.5, \"GAA\":11.8, \"GAG\":44.6,\n",
        "    \"GGU\":9.2, \"GGC\":55.9, \"GGA\":7.8, \"GGG\":14.4,\n",
        "}\n",
        "# Convert to DNA\n",
        "codon_usage_dna = {k.replace(\"U\", \"T\"): v for k, v in codon_usage.items()}\n",
        "# Convert raw counts (from Kazusa codon usage table) to relative frequencies\n",
        "weights = {}\n",
        "aa_table = {}\n",
        "for codon, freq in codon_usage_dna.items():\n",
        "    aa = str(Seq(codon).translate())\n",
        "    aa_table.setdefault(aa, []).append((codon, freq))\n",
        "for aa, codons in aa_table.items():\n",
        "    max_freq = max(freq for codon, freq in codons)\n",
        "    for codon, freq in codons:\n",
        "        weights[codon] = freq / max_freq if max_freq > 0 else 0\n",
        "# Don't know why but the CodonUsage module from Bio.SeqUtils can't be imported...\n",
        "# We have to define the function to calculate CAI... (and GC content as well,,,)\n",
        "def cai(seq, weights):\n",
        "    seq = seq.upper()\n",
        "    codons = [seq[i:i+3] for i in range(0, len(seq), 3)]\n",
        "    wi = []\n",
        "    for codon in codons:\n",
        "        if codon in weights:\n",
        "            wi.append(weights[codon])\n",
        "    if not wi:\n",
        "        return 0.0\n",
        "    return math.exp(sum(math.log(w) for w in wi if w > 0) / len(wi))\n",
        "def gc_fraction(seq):\n",
        "    seq = seq.upper()\n",
        "    g = seq.count(\"G\")\n",
        "    c = seq.count(\"C\")\n",
        "    total = len(seq)\n",
        "    return (g + c) / total if total > 0 else 0.0\n",
        "initial_gc = gc_fraction(initial_seq)\n",
        "print(f'GC Content of the initial sequence: {initial_gc}')\n",
        "val_results = []\n",
        "for i, seq in enumerate(optimized_sequences['best_seq'], start=1):\n",
        "    seq_diffs = [(j, a, b) for j, (a, b) in enumerate(zip(seq, initial_seq)) if a != b]\n",
        "    print(f'Substitutions in seq_{i}: {seq_diffs}')\n",
        "    # Compute CAI\n",
        "    cai_value = cai(seq, weights)\n",
        "    # Compute GC content\n",
        "    gc_content = gc_fraction(Seq(seq)) * 100\n",
        "    val_results.append({\n",
        "        'sequence_id': f'opt_{i}',\n",
        "        'CAI': cai_value,\n",
        "        'GC_content': gc_content\n",
        "    })\n",
        "val_df = pd.DataFrame(val_results)\n",
        "print(val_df)\n",
        "\n",
        "# Scatterplot for visualization\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(val_df['GC_content'], val_df['CAI'])\n",
        "for _, row in val_df.iterrows():\n",
        "    plt.text(row['GC_content']+0.01, row['CAI'], row['sequence_id'])\n",
        "plt.xlabel('GC content (%)')\n",
        "plt.ylabel('CAI')\n",
        "host_gc = 69.94\n",
        "plt.axvline(x=host_gc, linestyle='--', label=f'Host GC content: {host_gc:.2f}%')\n",
        "plt.title('Host-compatibility of optimized sequences')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcFjs8bEp3m9"
      },
      "outputs": [],
      "source": [
        "# Section 7: structural verification - stability (pLDDT) and alignment with initial sequence via TM-score and PyMol `align`\n",
        "\n",
        "# Upload initial and optimized protein sequences to ColabFold for PDBs and pLDDT scores\n",
        "# Upload predicted PDBs to PyMOL\n",
        "\n",
        "# Use TM-align to calculate TM-scores with the reference (unoptimized) sequence\n",
        "# https://zhanggroup.org/TM-align/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v41lVs0dz8kI"
      },
      "source": [
        "## Structural predictions\n",
        "\n",
        "Results given by AlphaFold2, ran via [ColabFold](https://github.com/sokrypton/ColabFold/\n",
        "\n",
        "**Initial (reference) protein sequence**: pLDDT=94.4, pTM=0.916\n",
        "\n",
        "![plot0](./img/init_pr.png)\n",
        "\n",
        "![plot0](./img/init_model3.png)\n",
        "\n",
        "![plddt0](./img/Optim1_91ca1_plddt.png)\n",
        "\n",
        "![coverage0](./img/Optim1_91ca1_coverage.png)\n",
        "\n",
        "Used as reference to align with predicted structures of the following optimized sequences (I only tested two of them): \n",
        "\n",
        "**Optimized sequence #1**: pLDDT=94.4, pTM=0.915, RMSD=0.215, TM-score=0.9835\n",
        "\n",
        "![align1](./img/align_pr1.png)\n",
        "\n",
        "![plot1](./img/Optim1_model5.png)\n",
        "\n",
        "![plddt1](./img/Optim1_91ca1_plddt.png)\n",
        "\n",
        "![coverage1](./img/Optim1_91ca1_coverage.png)\n",
        "\n",
        "![tm1](./img/tm1.png)\n",
        "\n",
        "\n",
        "**Optimized sequence #4**: pLDDT=94.6, pTM=0.917, RMSD=0.203, TM-score=0.9801\n",
        "\n",
        "![align4](./img/align_pr4.png)\n",
        "\n",
        "![plot4](./img/Optim4_model3.png)\n",
        "\n",
        "![plddt4](./img/Optim4_7aaf1_0_plddt.png)\n",
        "\n",
        "![coverage4](./img/Optim4_7aaf1_0_coverage.png)\n",
        "\n",
        "![tm4](./img/tm4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHnASFiHz8z8"
      },
      "source": [
        "## Limitations of this computational pipeline\n",
        "\n",
        "*(just a demo to play around!)*\n",
        "\n",
        "1. **The greatest one, identified only after running the whole thing - insignificant actual improvement on the metrics.** Sad.\n",
        "\n",
        "2. Absence of wet-lab validation. The optimized sequence is very likely to fail when synthesized and expressed *in vivo*.\n",
        "\n",
        "3. Training data is limited to a maximum of only 512 tokens per sequence due to GPU OOMs... (so upsetting). The model now fails to capture long-range dependencies, and its understanding of 'host-likeness' is skewed towards properties of short proteins. However, the full-sequence length of our target alkB gene during inference is much longer...\n",
        "\n",
        "4. Oversimplification. The optimization relies on a single metric (the generative model's negative log-likelihood), whereas a more robust score should combine multiple measures (CAI, pLDDT, etc). Moreover, the illustration on the active site preservation is way too naive.\n",
        "\n",
        "5. Hyperparameters might be poorly chosen. This can cause the search in the sequence space to be trapped in local optima, even though the MH-MCMC algorithm (as opposed to a greedy search) is designed to escape them.\n",
        "\n",
        "---\n",
        "\n",
        "## Background information about our iGEM project\n",
        "\n",
        "Our project aims to mitigate plastic pollution by engineering *Streptomyces lividans*, a G+ bacterium abundant in soil, to degrade low-density polyethylene (LDPE). We plan to achieve this by introducing the alkane monooxygenase gene (alkB) from *Rhodococcus erythropolis* and evaluating its efficacy in LDPE breakdown."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
